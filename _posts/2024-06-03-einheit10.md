---
title: "Nachtrag: Lerneinheit 10: Linked Data"
date: 2024-06-03
---
Das ist bereits der letzte Eintrag zu einer Lerneinheit in diesem Modul. In der heutigen Unterrichtseinheit drehte sich alles um das Thema Linked Data und dessen spezifische Ausprägungen, wie Linked Open Data (LOD) und Linked Open Usable Data (LOUD). Zudem haben wir uns mit aktuellen Datenmodellen für Metadaten, insbesondere BIBFRAME und Records in Context (RiC), auseinandergesetzt. Spannend fand ich den Hinweis, dass die Umstellung auf neue Standards nicht wirklich dringlich, "da man alles auch irgendwie mit den alten Standards lösen kann".
Ein weiterer wichtiger Bestandteil der Sitzung war die praktische Anwendung der Anreicherung von Metadaten mithilfe von OpenRefine und Wikidata.

**Was war neu für mich?**
Obwohl ich aus anderen Modulen bereits grundlegende Kenntnisse über Linked Data hatte, war die  Unterscheidung zwischen **LOD und LOUD** neu für mich. LOD betont die Offenheit der Daten, während LOUD den zusätzlichen Fokus auf die Nutzbarkeit dieser offenen Daten legt. Dies bedeutet, dass LOUD nicht nur vernetzt und offen, sondern auch direkt für Software-Anwendungen nutzbar sein muss, um einen echten Mehrwert zu bieten. 
Wikidata war mir im Zusammenhang mit der SPARQL-Abfragesprache aus dem Modul Grundlagen Semantische Technologien bereits ein Begriff. Jedoch war das ganze Konzept der **Reconciliation** neu für mich: Dabei bietet z.B. OpenRefine eine Funktion zum Abgleich der eigenen Daten mit Wikidata. Durch "Suggest" und "Extend Data" kann ausserdem im Dialog aufgrund der eigenen Daten Änderungen vorgeschlagen werden.
**[ORKG](https://ask.orkg.org) als LLM (Large Language Model)**: ORKG steht für Open Research Knowledge Graph. Es handelt sich um eine Plattform und ein Projekt, das darauf abzielt, wissenschaftliches Wissen in Form von strukturierten Daten zu erfassen, zu verknüpfen und zu visualisieren. Hab das gleich für meine Bachelor Thesis getestet und habe effektiv neue Literatur gefunden :-)

![orkg](https://github.com/user-attachments/assets/77171641-8475-47c2-89c9-fd6f1f6d5f37)


**Wie bin ich mit den Arbeitsaufträgen klar gekommen?**
Die theoretischen Grundlagen und Konzepte von Linked Data, LOD und LOUD konnte ich gut nachvollziehen, da ich diese bereits ansatzweise in früheren Modulen behandelt hatte. Auch die Einführung und Erklärung der Datenmodelle BIBFRAME und RiC waren gut strukturiert und verständlich, was mir das Lernen erleichtert hat. Die Metapher „vom Baum zum Netz“ für RiC hat mir geholfen, die Transformation von hierarchischen zu vernetzten Datenstrukturen besser zu verstehen.
Die praktische Anwendung der Anreicherung von Metadaten mit OpenRefine und Wikidata war herausfordernd. Besonders die Notwendigkeit korrekter und einheitlicher Daten stellte sich als Hürde heraus, da falsche Identifier zu Falschzuordnungen führen können. Hier zeigte sich, dass die Theorie zwar klar ist, die praktische Umsetzung jedoch durchaus komplex und fehleranfällig sein kann. Hilfreich war hier die Möglichkeit, die Aufnahme zu stoppen und in meinem eigenen Tempo zu arbeiten.

**Was blieb unklar?**
Im Zusammenhang mit LOUD gab es einen längeren Exkurs zum json- resp. json-ld-Dateiformat - das muss ich mir nochmals in Ruhe anschauen, da wir auch im Modul Frontend Development eine json-Datei einbinden werden.


**Verwendete Quellen:**
- [Linked Open Data](https://openall.info)
- [Linked Data](https://data.europa.eu)
- [VSA-AAS RiC](https://vsa-aas.ch)
- [Arbido RiC](https://arbido.ch)
